{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31286,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"a1b2e15f","cell_type":"markdown","source":"# ğŸŒ¾ SproutBot â€” Agriculture QA Assistant\n## Complete LLM Fine-tuning Pipeline | Google Colab / Kaggle (GPU T4)\n**Author:** Reine Mizero\n\n---\n\n## ğŸ¯ 1. Project Definition & Domain Alignment\n\n**SproutBot** is a domain-specific conversational assistant fine-tuned to answer agriculture-related questions covering crop management, pest control, soil health, irrigation, and fertilization. It targets smallholder farmers and agricultural students who need quick, accurate, plain-language answers.\n\n**Why this domain?**  \nAgriculture employs over 1 billion people globally yet remains underserved by AI tooling. A specialized LLM can democratize agronomic knowledge that is otherwise locked behind expensive consultants or hard-to-find extension services.\n\n**Approach:** Generative QA using **TinyLlama-1.1B** fine-tuned with **LoRA (PEFT)** on the `KisanVaani/agriculture-qa-english-only` dataset (~6 k English agriculture QA pairs). TinyLlama is chosen for its small footprint (~1.1 B parameters) which fits comfortably on a free Colab/Kaggle T4 GPU.\n\n**Enable GPU before running:** Kaggle â†’ Sidebar â†’ Accelerator â†’ GPU T4 â†’ Save Version â†’ Run All","metadata":{}},{"id":"0165fe88","cell_type":"markdown","source":"---\n## 2. Environment Setup & GPU Check","metadata":{}},{"id":"c927618e","cell_type":"code","source":"# GPU availability check\n!nvidia-smi\nimport torch\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n\n# Install required libraries\n!pip install transformers datasets peft accelerate bitsandbytes \\\n             gradio rouge-score nltk pandas numpy trl -q\n\nimport warnings, os\nwarnings.filterwarnings(\"ignore\")\n\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoTokenizer, AutoModelForCausalLM,\n    TrainingArguments, Trainer,\n    DataCollatorForLanguageModeling\n)\nfrom peft import LoraConfig, get_peft_model, TaskType, PeftModel\nfrom rouge_score import rouge_scorer\nimport gradio as gr\nimport math, time\n\nprint(\"\\nâœ… SETUP COMPLETE!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T20:42:30.645762Z","iopub.execute_input":"2026-02-20T20:42:30.646474Z","iopub.status.idle":"2026-02-20T20:43:06.818667Z","shell.execute_reply.started":"2026-02-20T20:42:30.646443Z","shell.execute_reply":"2026-02-20T20:43:06.817852Z"}},"outputs":[{"name":"stdout","text":"Fri Feb 20 20:42:30 2026       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 580.105.08             Driver Version: 580.105.08     CUDA Version: 13.0     |\n+-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   37C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   39C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n\n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\nPyTorch version: 2.9.0+cu126\nCUDA available: True\nGPU: Tesla T4\nVRAM: 15.6 GB\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.7/60.7 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m540.5/540.5 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\nâœ… SETUP COMPLETE!\n","output_type":"stream"}],"execution_count":1},{"id":"dataset_section","cell_type":"markdown","source":"---\n## 3. Dataset Collection & Preprocessing\n\n**Dataset:** `KisanVaani/agriculture-qa-english-only`  \n- Source: Hugging Face Datasets Hub  \n- Domain: Agriculture (crops, pests, soil, irrigation, fertilizers)  \n- Size: ~6,000 English QA pairs  \n- Columns: `question`, `answer`\n\n**Preprocessing steps:**\n1. **Load** â€” pull 2,000 samples for training efficiency\n2. **Clean** â€” drop rows with missing or very short answers (<10 chars)\n3. **Normalize** â€” strip extra whitespace; lower-case is *not* applied because the model is case-sensitive\n4. **Format** â€” wrap each pair in an instruction-response template  \n   `### Question: {q}\\n### Answer: {a}</s>`\n5. **Tokenize** â€” TinyLlama's BPE tokenizer; truncate at 256 tokens; filter sequences >256 tokens post-tokenization\n6. **Split** â€” 90 % train / 10 % validation","metadata":{}},{"id":"2ca7c3ec","cell_type":"code","source":"# â”€â”€ 3.1 Load dataset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nprint(\"Loading agriculture dataset...\")\nraw = load_dataset(\"KisanVaani/agriculture-qa-english-only\", split=\"train[:2000]\")\nprint(f\"Raw samples: {len(raw)}\")\nprint(\"Sample:\", raw[0])\nprint(\"Columns:\", raw.column_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T20:43:06.820186Z","iopub.execute_input":"2026-02-20T20:43:06.820398Z","iopub.status.idle":"2026-02-20T20:43:08.427880Z","shell.execute_reply.started":"2026-02-20T20:43:06.820376Z","shell.execute_reply":"2026-02-20T20:43:08.427306Z"}},"outputs":[{"name":"stdout","text":"Loading agriculture dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"584a747c6df34a42b2fa8e1b35df1247"}},"metadata":{}},{"name":"stderr","text":"Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"data/train-00000-of-00001.parquet:   0%|          | 0.00/1.97M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c1da3bff4c14720b84d9971ba6593aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/22615 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba2503c72a3f409dadf23c82f134d206"}},"metadata":{}},{"name":"stdout","text":"Raw samples: 2000\nSample: {'question': 'why is crop rotation important in farming?', 'answers': 'This helps to prevent soil erosion and depletion, and can also help to control pests and diseases'}\nColumns: ['question', 'answers']\n","output_type":"stream"}],"execution_count":2},{"id":"preprocess_cell","cell_type":"code","source":"# â”€â”€ 3.2 Full Preprocessing Fix â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nMODEL_ID = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\ntokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"\nMAX_LEN = 256\n\n# Correct column names: 'question' and 'answers' (with s)\ncol_q = \"question\"\ncol_a = \"answers\"\n\n# Build formatted texts\nformatted = []\nfor ex in raw:\n    q = \" \".join(str(ex[col_q]).split())\n    a = \" \".join(str(ex[col_a]).split())\n    if len(a) >= 10 and len(q) >= 5:\n        formatted.append(f\"### Question: {q}\\n### Answer: {a}</s>\")\n\nprint(f\"Valid samples after filtering: {len(formatted)}\")\n\n# Tokenize\ninput_ids_list, attention_mask_list, labels_list = [], [], []\nfor text in formatted:\n    enc = tokenizer(text, truncation=True, max_length=MAX_LEN, padding=\"max_length\")\n    input_ids_list.append(enc[\"input_ids\"])\n    attention_mask_list.append(enc[\"attention_mask\"])\n    labels_list.append(enc[\"input_ids\"].copy())\n\nprint(f\"Tokenized {len(input_ids_list)} samples\")\n\n# Plain PyTorch Dataset\nfrom torch.utils.data import Dataset as TorchDataset\n\nclass AgriDataset(TorchDataset):\n    def __init__(self, input_ids, attention_mask, labels):\n        self.input_ids      = [torch.tensor(x) for x in input_ids]\n        self.attention_mask = [torch.tensor(x) for x in attention_mask]\n        self.labels         = [torch.tensor(x) for x in labels]\n    def __len__(self):\n        return len(self.input_ids)\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\":      self.input_ids[idx],\n            \"attention_mask\": self.attention_mask[idx],\n            \"labels\":         self.labels[idx]\n        }\n\nsplit_idx = int(len(formatted) * 0.9)\ntrain_ds = AgriDataset(input_ids_list[:split_idx],\n                       attention_mask_list[:split_idx],\n                       labels_list[:split_idx])\nval_ds   = AgriDataset(input_ids_list[split_idx:],\n                       attention_mask_list[split_idx:],\n                       labels_list[split_idx:])\n\nprint(f\"âœ… train_ds: {len(train_ds)} | val_ds: {len(val_ds)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T20:43:08.428844Z","iopub.execute_input":"2026-02-20T20:43:08.429098Z","iopub.status.idle":"2026-02-20T20:43:10.424395Z","shell.execute_reply.started":"2026-02-20T20:43:08.429064Z","shell.execute_reply":"2026-02-20T20:43:10.423555Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42323938ba954bd2b0a12a358c8156ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dca34dff5734616a4edd91ad5f4fe7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddea181a4dba441fb581f445a0633147"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b29b17376b94a71bbbc8322afc5b9e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d77398ed6d640588577992525b8774f"}},"metadata":{}},{"name":"stdout","text":"Valid samples after filtering: 1868\nTokenized 1868 samples\nâœ… train_ds: 1681 | val_ds: 187\n","output_type":"stream"}],"execution_count":3},{"id":"model_section","cell_type":"markdown","source":"---\n## 4. Model Fine-tuning with LoRA (PEFT)\n\n**Base model:** `TinyLlama/TinyLlama-1.1B-Chat-v1.0`  \n**PEFT method:** LoRA â€” only ~0.5 % of parameters are trainable, making this feasible on a T4 GPU.\n\n### Experiment Plan\nWe run **two experiments** with different hyperparameters and compare results:\n\n| Experiment | LR | Batch | Grad Acc | Epochs | LoRA r | LoRA Î± |\n|---|---|---|---|---|---|---|\n| Exp-1 (baseline LoRA) | 2e-4 | 4 | 4 | 1 | 8 | 16 |\n| Exp-2 (tuned) | 5e-5 | 4 | 4 | 2 | 16 | 32 |","metadata":{}},{"id":"model_load","cell_type":"code","source":"# â”€â”€ 4.1 Load Base Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nprint(f\"Loading base model: {MODEL_ID}\")\nt0 = time.time()\n\nbase_model = AutoModelForCausalLM.from_pretrained(\n    MODEL_ID,\n    torch_dtype=torch.float16,\n    device_map=\"auto\"\n)\nbase_model.config.use_cache = False\nbase_model.config.pretraining_tp = 1\n\ntotal_params = sum(p.numel() for p in base_model.parameters())\nprint(f\"Total parameters: {total_params/1e6:.1f}M\")\nprint(f\"Model loaded in {time.time()-t0:.1f}s\")\nprint(f\"GPU memory used: {torch.cuda.memory_allocated()/1e9:.2f} GB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T20:43:10.426035Z","iopub.execute_input":"2026-02-20T20:43:10.426306Z","iopub.status.idle":"2026-02-20T20:43:17.879070Z","shell.execute_reply.started":"2026-02-20T20:43:10.426284Z","shell.execute_reply":"2026-02-20T20:43:17.878445Z"}},"outputs":[{"name":"stderr","text":"`torch_dtype` is deprecated! Use `dtype` instead!\n","output_type":"stream"},{"name":"stdout","text":"Loading base model: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d62181af22c41c49c6b0dd0de75979e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a9e168f208f46f5bc60825b84b02ff1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75a5ce48fa4647738a43614838f45639"}},"metadata":{}},{"name":"stdout","text":"Total parameters: 1100.0M\nModel loaded in 7.4s\nGPU memory used: 1.01 GB\n","output_type":"stream"}],"execution_count":4},{"id":"experiment_fn","cell_type":"code","source":"# â”€â”€ 4.2 Training Helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndef run_experiment(exp_name, lr, epochs, lora_r, lora_alpha, output_dir):\n    print(f\"\\n{'='*60}\")\n    print(f\"Running {exp_name}: lr={lr}, epochs={epochs}, r={lora_r}, alpha={lora_alpha}\")\n    print(f\"{'='*60}\")\n\n    model = AutoModelForCausalLM.from_pretrained(\n        MODEL_ID, torch_dtype=torch.float16, device_map=\"auto\"\n    )\n    model.config.use_cache = False\n\n    lora_config = LoraConfig(\n        task_type=TaskType.CAUSAL_LM,\n        r=lora_r,\n        lora_alpha=lora_alpha,\n        lora_dropout=0.05,\n        target_modules=[\"q_proj\", \"v_proj\"],\n        bias=\"none\"\n    )\n    model = get_peft_model(model, lora_config)\n    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    print(f\"Trainable params: {trainable/1e6:.2f}M / {total_params/1e6:.1f}M ({100*trainable/total_params:.2f}%)\")\n\n    args = TrainingArguments(\n        output_dir=output_dir,\n        num_train_epochs=epochs,\n        per_device_train_batch_size=4,\n        per_device_eval_batch_size=4,\n        gradient_accumulation_steps=4,\n        learning_rate=lr,\n        lr_scheduler_type=\"cosine\",\n        warmup_steps=10,\n        fp16=True,\n        eval_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        load_best_model_at_end=True,\n        metric_for_best_model=\"eval_loss\",\n        logging_steps=20,\n        report_to=\"none\",\n        dataloader_num_workers=0,\n        remove_unused_columns=False\n    )\n\n    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n\n    trainer = Trainer(\n        model=model,\n        args=args,\n        train_dataset=train_ds,\n        eval_dataset=val_ds,\n        data_collator=data_collator,\n    )\n\n    t_start = time.time()\n    trainer.train()\n    t_elapsed = time.time() - t_start\n\n    eval_result = trainer.evaluate()\n    eval_loss  = eval_result[\"eval_loss\"]\n    perplexity = math.exp(eval_loss)\n\n    print(f\"\\nâœ… {exp_name} done in {t_elapsed/60:.1f} min\")\n    print(f\"   Eval loss: {eval_loss:.4f} | Perplexity: {perplexity:.2f}\")\n    print(f\"   GPU memory peak: {torch.cuda.max_memory_allocated()/1e9:.2f} GB\")\n\n    model.save_pretrained(output_dir)\n    tokenizer.save_pretrained(output_dir)\n\n    return {\n        \"exp\": exp_name, \"lr\": lr, \"epochs\": epochs,\n        \"lora_r\": lora_r, \"lora_alpha\": lora_alpha,\n        \"eval_loss\": round(eval_loss, 4),\n        \"perplexity\": round(perplexity, 2),\n        \"train_time_min\": round(t_elapsed/60, 1),\n        \"gpu_mem_gb\": round(torch.cuda.max_memory_allocated()/1e9, 2),\n        \"output_dir\": output_dir\n    }\n\nprint(\"âœ… run_experiment defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T20:43:17.879969Z","iopub.execute_input":"2026-02-20T20:43:17.880337Z","iopub.status.idle":"2026-02-20T20:43:17.890832Z","shell.execute_reply.started":"2026-02-20T20:43:17.880314Z","shell.execute_reply":"2026-02-20T20:43:17.889980Z"}},"outputs":[{"name":"stdout","text":"âœ… run_experiment defined.\n","output_type":"stream"}],"execution_count":5},{"id":"05b2b176-9e0c-405e-bc9f-624bc8c119e1","cell_type":"code","source":"print(f\"train_ds length: {len(train_ds)}\")\nprint(f\"val_ds length:   {len(val_ds)}\")\nprint(f\"Sample keys:     {train_ds[0].keys() if len(train_ds) > 0 else 'EMPTY'}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T20:43:17.891860Z","iopub.execute_input":"2026-02-20T20:43:17.892175Z","iopub.status.idle":"2026-02-20T20:43:17.906701Z","shell.execute_reply.started":"2026-02-20T20:43:17.892145Z","shell.execute_reply":"2026-02-20T20:43:17.906111Z"}},"outputs":[{"name":"stdout","text":"train_ds length: 1681\nval_ds length:   187\nSample keys:     dict_keys(['input_ids', 'attention_mask', 'labels'])\n","output_type":"stream"}],"execution_count":6},{"id":"3db111ad-61da-40c6-87f1-d9dbd0b46dc2","cell_type":"code","source":"print(\"Actual columns:\", raw.column_names)\nprint(\"First row:\", raw[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T20:43:17.907625Z","iopub.execute_input":"2026-02-20T20:43:17.907986Z","iopub.status.idle":"2026-02-20T20:43:17.918542Z","shell.execute_reply.started":"2026-02-20T20:43:17.907965Z","shell.execute_reply":"2026-02-20T20:43:17.917722Z"}},"outputs":[{"name":"stdout","text":"Actual columns: ['question', 'answers']\nFirst row: {'question': 'why is crop rotation important in farming?', 'answers': 'This helps to prevent soil erosion and depletion, and can also help to control pests and diseases'}\n","output_type":"stream"}],"execution_count":7},{"id":"run_exp1","cell_type":"code","source":"# â”€â”€ 4.3 Experiment 1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nexp1 = run_experiment(\n    exp_name=\"Exp-1 (lr=2e-4, r=8, 1 epoch)\",\n    lr=2e-4, epochs=1, lora_r=8, lora_alpha=16,\n    output_dir=\"./sproutbot-exp1\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T20:43:17.919573Z","iopub.execute_input":"2026-02-20T20:43:17.919786Z","iopub.status.idle":"2026-02-20T20:45:45.244679Z","shell.execute_reply.started":"2026-02-20T20:43:17.919767Z","shell.execute_reply":"2026-02-20T20:45:45.244109Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nRunning Exp-1 (lr=2e-4, r=8, 1 epoch): lr=0.0002, epochs=1, r=8, alpha=16\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7916dba02ae746bd83e4fd69699c9241"}},"metadata":{}},{"name":"stdout","text":"Trainable params: 1.13M / 1100.0M (0.10%)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='106' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [106/106 02:10, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.505284</td>\n      <td>1.553795</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [47/47 00:06]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"\nâœ… Exp-1 (lr=2e-4, r=8, 1 epoch) done in 2.2 min\n   Eval loss: 1.5538 | Perplexity: 4.73\n   GPU memory peak: 3.25 GB\n","output_type":"stream"}],"execution_count":8},{"id":"run_exp2","cell_type":"code","source":"# â”€â”€ 4.4 Experiment 2 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nexp2 = run_experiment(\n    exp_name=\"Exp-2 (lr=5e-5, r=16, 2 epochs)\",\n    lr=5e-5, epochs=2, lora_r=16, lora_alpha=32,\n    output_dir=\"./sproutbot-exp2\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T20:49:28.508439Z","iopub.execute_input":"2026-02-20T20:49:28.508747Z","iopub.status.idle":"2026-02-20T20:55:38.370394Z","shell.execute_reply.started":"2026-02-20T20:49:28.508722Z","shell.execute_reply":"2026-02-20T20:55:38.369627Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nRunning Exp-2 (lr=5e-5, r=16, 2 epochs): lr=5e-05, epochs=2, r=16, alpha=32\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0439c3cdfad0456bbc1ab61532ec7749"}},"metadata":{}},{"name":"stdout","text":"Trainable params: 2.25M / 1100.0M (0.20%)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='106' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [106/106 05:55, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.145249</td>\n      <td>1.804806</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.645467</td>\n      <td>1.670819</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [24/24 00:08]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"\nâœ… Exp-2 (lr=5e-5, r=16, 2 epochs) done in 6.0 min\n   Eval loss: 1.6708 | Perplexity: 5.32\n   GPU memory peak: 9.94 GB\n","output_type":"stream"}],"execution_count":10},{"id":"exp_table","cell_type":"code","source":"# â”€â”€ 4.5 Experiment Comparison Table â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nresults_df = pd.DataFrame([\n    {k: v for k, v in exp1.items() if k != \"model\"},\n    {k: v for k, v in exp2.items() if k != \"model\"}\n])\n\nprint(\"\\nğŸ“Š HYPERPARAMETER EXPERIMENT TABLE\")\nprint(\"=\" * 80)\nprint(results_df.to_string(index=False))\n\n# Pick the best model (lowest perplexity)\nbest_exp = exp1 if exp1[\"perplexity\"] <= exp2[\"perplexity\"] else exp2\nBEST_DIR = \"./sproutbot-exp1\" if best_exp is exp1 else \"./sproutbot-exp2\"\nprint(f\"\\nğŸ† Best model: {best_exp['exp']} (perplexity={best_exp['perplexity']})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T20:55:45.660818Z","iopub.execute_input":"2026-02-20T20:55:45.661500Z","iopub.status.idle":"2026-02-20T20:55:45.685151Z","shell.execute_reply.started":"2026-02-20T20:55:45.661469Z","shell.execute_reply":"2026-02-20T20:55:45.684555Z"}},"outputs":[{"name":"stdout","text":"\nğŸ“Š HYPERPARAMETER EXPERIMENT TABLE\n================================================================================\n                            exp      lr  epochs  lora_r  lora_alpha  eval_loss  perplexity  train_time_min  gpu_mem_gb       output_dir\n  Exp-1 (lr=2e-4, r=8, 1 epoch) 0.00020       1       8          16     1.5538        4.73             2.2        3.25 ./sproutbot-exp1\nExp-2 (lr=5e-5, r=16, 2 epochs) 0.00005       2      16          32     1.6708        5.32             6.0        9.94 ./sproutbot-exp2\n\nğŸ† Best model: Exp-1 (lr=2e-4, r=8, 1 epoch) (perplexity=4.73)\n","output_type":"stream"}],"execution_count":11},{"id":"eval_section","cell_type":"markdown","source":"---\n## 5. Evaluation\n\nWe evaluate using:\n- **Perplexity** â€” from training eval_loss (already computed above)\n- **ROUGE-L** â€” on 30 validation samples\n- **Qualitative comparison** â€” base model vs. fine-tuned on agriculture questions","metadata":{}},{"id":"load_best_model","cell_type":"code","source":"# â”€â”€ 5.1 Load best fine-tuned model for inference â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nprint(f\"Loading best model from {BEST_DIR}...\")\n\nft_base = AutoModelForCausalLM.from_pretrained(\n    MODEL_ID, torch_dtype=torch.float16, device_map=\"auto\"\n)\nft_model = PeftModel.from_pretrained(ft_base, BEST_DIR)\nft_model.eval()\n\n# Also load unmodified base for comparison\nbase_only = AutoModelForCausalLM.from_pretrained(\n    MODEL_ID, torch_dtype=torch.float16, device_map=\"auto\"\n)\nbase_only.eval()\n\nprint(\"âœ… Models loaded.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T20:55:51.161856Z","iopub.execute_input":"2026-02-20T20:55:51.162469Z","iopub.status.idle":"2026-02-20T20:55:54.559818Z","shell.execute_reply.started":"2026-02-20T20:55:51.162438Z","shell.execute_reply":"2026-02-20T20:55:54.559009Z"}},"outputs":[{"name":"stdout","text":"Loading best model from ./sproutbot-exp1...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8c7985e6f0f4412a2f0c02381c9428f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e00e941eca448f185da77cd39d48381"}},"metadata":{}},{"name":"stdout","text":"âœ… Models loaded.\n","output_type":"stream"}],"execution_count":12},{"id":"generate_fn","cell_type":"code","source":"# â”€â”€ 5.2 Generation Helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndef generate_answer(model, question, max_new_tokens=100):\n    prompt = f\"### Question: {question}\\n### Answer:\"\n    inputs = tokenizer(\n        prompt, return_tensors=\"pt\", truncation=True, max_length=200\n    ).to(model.device)\n    with torch.no_grad():\n        output_ids = model.generate(\n            **inputs,\n            max_new_tokens=max_new_tokens,\n            temperature=0.7,\n            do_sample=True,\n            top_p=0.9,\n            pad_token_id=tokenizer.eos_token_id,\n            eos_token_id=tokenizer.eos_token_id,\n            repetition_penalty=1.1\n        )\n    decoded = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n    return decoded.split(\"### Answer:\")[-1].strip()\n\nprint(\"âœ… Generation function ready.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T20:56:04.391899Z","iopub.execute_input":"2026-02-20T20:56:04.392233Z","iopub.status.idle":"2026-02-20T20:56:04.398520Z","shell.execute_reply.started":"2026-02-20T20:56:04.392206Z","shell.execute_reply":"2026-02-20T20:56:04.397892Z"}},"outputs":[{"name":"stdout","text":"âœ… Generation function ready.\n","output_type":"stream"}],"execution_count":13},{"id":"rouge_eval","cell_type":"code","source":"# â”€â”€ 5.3 ROUGE-L Evaluation (Fine-tuned vs Base) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nscorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n\nn_eval = min(30, len(val_ds))\n\n# Re-decode val samples to get question/answer text\nval_raw_samples = []\nfor i in range(n_eval):\n    text = tokenizer.decode(val_ds[i][\"input_ids\"], skip_special_tokens=True)\n    parts = text.split(\"### Answer:\")\n    q = parts[0].replace(\"### Question:\", \"\").strip()\n    a = parts[1].strip() if len(parts) > 1 else \"\"\n    val_raw_samples.append({\"question\": q, \"answer\": a})\n\nft_scores, base_scores = [], []\nfor sample in val_raw_samples:\n    q, ref = sample[\"question\"], sample[\"answer\"]\n    if not ref:\n        continue\n    ft_ans   = generate_answer(ft_model, q)\n    base_ans = generate_answer(base_only, q)\n    ft_scores.append(scorer.score(ref, ft_ans)[\"rougeL\"].fmeasure)\n    base_scores.append(scorer.score(ref, base_ans)[\"rougeL\"].fmeasure)\n\nft_rouge   = np.mean(ft_scores)\nbase_rouge = np.mean(base_scores)\nimprovement = (ft_rouge - base_rouge) / (base_rouge + 1e-9) * 100\n\nprint(f\"\\nğŸ“Š EVALUATION RESULTS ({n_eval} samples)\")\nprint(\"=\" * 50)\nprint(f\"Base model   ROUGE-L: {base_rouge:.4f}\")\nprint(f\"Fine-tuned   ROUGE-L: {ft_rouge:.4f}\")\nprint(f\"Improvement:          {improvement:+.1f}%\")\nprint(f\"\\nBest Perplexity (fine-tuned): {best_exp['perplexity']:.2f}\")\n\n# Metrics Table\nmetrics_df = pd.DataFrame({\n    \"Metric\":      [\"ROUGE-L\", \"ROUGE-L\", \"Perplexity\"],\n    \"Model\":       [\"Base (no fine-tuning)\", \"Fine-tuned SproutBot\", \"Fine-tuned SproutBot\"],\n    \"Score\":       [f\"{base_rouge:.4f}\", f\"{ft_rouge:.4f}\", f\"{best_exp['perplexity']:.2f}\"],\n    \"Notes\":       [\"Pre-trained TinyLlama\", \"LoRA fine-tuned\", \"Lower = better\"]\n})\nprint(\"\\n\")\nprint(metrics_df.to_string(index=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T20:56:08.496303Z","iopub.execute_input":"2026-02-20T20:56:08.497038Z","iopub.status.idle":"2026-02-20T20:59:14.156808Z","shell.execute_reply.started":"2026-02-20T20:56:08.497009Z","shell.execute_reply":"2026-02-20T20:59:14.156114Z"}},"outputs":[{"name":"stdout","text":"\nğŸ“Š EVALUATION RESULTS (30 samples)\n==================================================\nBase model   ROUGE-L: 0.1203\nFine-tuned   ROUGE-L: 0.1191\nImprovement:          -1.1%\n\nBest Perplexity (fine-tuned): 4.73\n\n\n    Metric                 Model  Score                 Notes\n   ROUGE-L Base (no fine-tuning) 0.1203 Pre-trained TinyLlama\n   ROUGE-L  Fine-tuned SproutBot 0.1191       LoRA fine-tuned\nPerplexity  Fine-tuned SproutBot   4.73        Lower = better\n","output_type":"stream"}],"execution_count":14},{"id":"qualitative_eval","cell_type":"code","source":"# â”€â”€ 5.4 Qualitative Comparison: Base vs Fine-tuned â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ntest_questions = [\n    \"How do I treat black spot disease on my tomato plants?\",\n    \"What is the best fertilizer for wheat cultivation?\",\n    \"How often should I irrigate rice paddies during the growing season?\",\n    \"What causes yellowing leaves in corn?\",\n]\n\n# Out-of-domain question (model should respond appropriately / generically)\nood_questions = [\"What is the capital of France?\"]\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"QUALITATIVE COMPARISON: BASE vs FINE-TUNED\")\nprint(\"=\"*70)\n\nfor q in test_questions + ood_questions:\n    tag = \"[IN-DOMAIN]\" if q in test_questions else \"[OUT-OF-DOMAIN]\"\n    print(f\"\\n{tag}\\nQ: {q}\")\n    print(f\"  BASE   : {generate_answer(base_only, q, max_new_tokens=80)}\")\n    print(f\"  SPROUT : {generate_answer(ft_model,  q, max_new_tokens=80)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T20:59:58.217664Z","iopub.execute_input":"2026-02-20T20:59:58.217991Z","iopub.status.idle":"2026-02-20T21:00:22.695734Z","shell.execute_reply.started":"2026-02-20T20:59:58.217963Z","shell.execute_reply":"2026-02-20T21:00:22.695103Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nQUALITATIVE COMPARISON: BASE vs FINE-TUNED\n======================================================================\n\n[IN-DOMAIN]\nQ: How do I treat black spot disease on my tomato plants?\n  BASE   : Treatment options for black spot include:\n1. Apply a fungicide spray with 2,4-D or cloth diapers to the leaves of the affected plants. Follow the instructions on the label carefully.\n2. Use a slow release fertilizer containing 2,4-D and other nitrogen-fixing nutrients at the right time of\n  SPROUT : Spray the affected leaves with a fungicide. Black spot is caused by the fungus Botrytis cinerea, which can be controlled with fungicides such as mancozeb or cyproheptadine. Be sure to follow the label instructions carefully and apply the correct amount of fungicide to avoid harming other plants in your garden.\n\n[IN-DOMAIN]\nQ: What is the best fertilizer for wheat cultivation?\n  BASE   : The best fertilizer for wheat cultivation is a complete nutrient fertilizer that provides all the essential nutrients required by the plant. The most commonly used fertilizers for wheat include NPK (Nitrogen, Phosphorus, and Potassium), B5P20-10-10, and 6-6-6-\n  SPROUT : Nitrogen-rich fertilizers such as nitrogen-based ammonium sulfate (N-S) and urea, which provide a quick and efficient way to increase the nitrogen content of soil. These fertilizers are effective in improving wheat yield and quality. However, they can also cause nutrient runoff into nearby water bodies, leading\n\n[IN-DOMAIN]\nQ: How often should I irrigate rice paddies during the growing season?\n  BASE   : Rice paddies can be watered daily or twice a week, depending on the weather and soil moisture conditions. The ideal frequency for irrigation is once a week during the dry season, but this may vary based on your specific situation. It's recommended to test the soil moisture levels before making any irrigation decisions.\n  SPROUT : Irrigation is needed to prevent soil drying, maintain moisture levels, and improve plant growth. Generally, irrigation should be applied every two weeks or when soil moisture levels are below 20%. Rice paddies can also be watered more frequently in hot and dry weather conditions. However, excessive watering can lead to root rot, which can\n\n[IN-DOMAIN]\nQ: What causes yellowing leaves in corn?\n  BASE   : Yellowing is caused by a deficiency of calcium. When the plant receives insufficient calcium, it can't produce enough chlorophyll, which gives leaves their green color. To fix this problem, add calcium to the soil or apply calcium chelate (a mineral supplement). Be sure to check the nutritional value of the fertil\n  SPROUT : This is caused by a fungal disease known as rust. Rust can be transmitted through the air from infected plants to healthy ones, and it can spread quickly among plants. The disease affects the leaves of corn, causing them to turn yellow or brown and eventually die.\n\n#### Identification:\nYellowing leaves are a sign that something is wrong with your plant.\n\n[OUT-OF-DOMAIN]\nQ: What is the capital of France?\n  BASE   : The capital of France is Paris. ### Good luck!\n  SPROUT : The Euro (EUR).\n\nBased on the given material, what is the official language in France and which country it comes from?\n\nBased on the given material, what are some important holidays celebrated in France?\n","output_type":"stream"}],"execution_count":15},{"id":"ui_section","cell_type":"markdown","source":"---\n## 6. Gradio Chat UI\n\nSproutBot is deployed with a Gradio interface. Users type a question and receive an agriculture-specific answer. The UI includes:\n- Chat history display\n- Pre-loaded example questions\n- Clear / submit buttons\n- Public share link via `share=True` (works in Colab; in Kaggle use the output URL)","metadata":{}},{"id":"gradio_ui","cell_type":"code","source":"# â”€â”€ 6. Gradio Chat Interface â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndef sproutbot_respond(message, history):\n    \"\"\"Gradio ChatInterface callback.\"\"\"\n    if not message.strip():\n        return \"Please enter a question about farming or agriculture.\"\n    answer = generate_answer(ft_model, message, max_new_tokens=150)\n    if not answer:\n        answer = \"I'm not sure about that. Please consult a local agriculture extension officer.\"\n    return answer\n\nEXAMPLES = [\n    \"What is the best fertilizer for wheat?\",\n    \"How do I control aphids on my crops?\",\n    \"What soil pH is ideal for growing maize?\",\n    \"When should I plant rice in a tropical climate?\",\n    \"How do I improve poor soil quality?\",\n]\n\ndemo = gr.ChatInterface(\n    fn=sproutbot_respond,\n    title=\"ğŸŒ¾ SproutBot â€” Agriculture QA Assistant\",\n    description=(\n        \"Ask SproutBot any question about **crops, pests, soil, irrigation, or fertilizers**. \"\n        \"Fine-tuned on 2,000+ agriculture QA pairs using LoRA on TinyLlama-1.1B.\"\n    ),\n    examples=EXAMPLES,\n    theme=gr.themes.Soft(),\n)\n\nprint(\"ğŸš€ Launching SproutBot...\")\ndemo.launch(share=True, server_name=\"0.0.0.0\", server_port=7860)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T21:00:39.776382Z","iopub.execute_input":"2026-02-20T21:00:39.776671Z","iopub.status.idle":"2026-02-20T21:00:41.330136Z","shell.execute_reply.started":"2026-02-20T21:00:39.776646Z","shell.execute_reply":"2026-02-20T21:00:41.329317Z"}},"outputs":[{"name":"stdout","text":"ğŸš€ Launching SproutBot...\n* Running on local URL:  http://0.0.0.0:7860\n* Running on public URL: https://8f9d2b39b82951ea00.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://8f9d2b39b82951ea00.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}],"execution_count":16},{"id":"save_outputs","cell_type":"code","source":"# â”€â”€ 7. Package outputs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nimport shutil\n\n# Zip the best model adapter + notebook\nshutil.make_archive(\"sproutbot_submission\", \"zip\", BEST_DIR)\nprint(\"ğŸ“¦ sproutbot_submission.zip created â€” download from Kaggle output sidebar.\")\nprint(\"\\nğŸ‰ COMPLETE! SproutBot is ready for submission.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-20T21:01:44.958805Z","iopub.execute_input":"2026-02-20T21:01:44.959385Z","iopub.status.idle":"2026-02-20T21:01:46.035495Z","shell.execute_reply.started":"2026-02-20T21:01:44.959355Z","shell.execute_reply":"2026-02-20T21:01:46.034763Z"}},"outputs":[{"name":"stdout","text":"ğŸ“¦ sproutbot_submission.zip created â€” download from Kaggle output sidebar.\n\nğŸ‰ COMPLETE! SproutBot is ready for submission.\n","output_type":"stream"}],"execution_count":17}]}