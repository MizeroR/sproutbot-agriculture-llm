{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31286,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"a1b2e15f","cell_type":"markdown","source":"# ðŸŒ¾ SproutBot â€” Agriculture QA Assistant\n## Complete LLM Fine-tuning Pipeline | Google Colab / Kaggle (GPU T4)\n**Author:** Reine Mizero\n\n---\n\n## ðŸŽ¯ 1. Project Definition & Domain Alignment\n\n**SproutBot** is a domain-specific conversational assistant fine-tuned to answer agriculture-related questions covering crop management, pest control, soil health, irrigation, and fertilization. It targets smallholder farmers and agricultural students who need quick, accurate, plain-language answers.\n\n**Why this domain?**  \nAgriculture employs over 1 billion people globally yet remains underserved by AI tooling. A specialized LLM can democratize agronomic knowledge that is otherwise locked behind expensive consultants or hard-to-find extension services.\n\n**Approach:** Generative QA using **TinyLlama-1.1B** fine-tuned with **LoRA (PEFT)** on the `KisanVaani/agriculture-qa-english-only` dataset (~6 k English agriculture QA pairs). TinyLlama is chosen for its small footprint (~1.1 B parameters) which fits comfortably on a free Colab/Kaggle T4 GPU.\n\n**Enable GPU before running:** Kaggle â†’ Sidebar â†’ Accelerator â†’ GPU T4 â†’ Save Version â†’ Run All","metadata":{}},{"id":"0165fe88","cell_type":"markdown","source":"---\n## 2. Environment Setup & GPU Check","metadata":{}},{"id":"c927618e","cell_type":"code","source":"# GPU availability check\n!nvidia-smi\nimport torch\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n\n# Install required libraries\n!pip install transformers datasets peft accelerate bitsandbytes \\\n             gradio rouge-score nltk pandas numpy trl -q\n\nimport warnings, os\nwarnings.filterwarnings(\"ignore\")\n\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoTokenizer, AutoModelForCausalLM,\n    TrainingArguments, Trainer,\n    DataCollatorForLanguageModeling\n)\nfrom peft import LoraConfig, get_peft_model, TaskType, PeftModel\nfrom rouge_score import rouge_scorer\nimport gradio as gr\nimport math, time\n\nprint(\"\\nâœ… SETUP COMPLETE!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T20:38:34.128765Z","iopub.execute_input":"2026-02-19T20:38:34.129578Z","iopub.status.idle":"2026-02-19T20:38:39.018356Z","shell.execute_reply.started":"2026-02-19T20:38:34.129537Z","shell.execute_reply":"2026-02-19T20:38:39.017349Z"}},"outputs":[{"name":"stdout","text":"Thu Feb 19 20:38:34 2026       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 580.105.08             Driver Version: 580.105.08     CUDA Version: 13.0     |\n+-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   68C    P0             30W /   70W |    4409MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   52C    P0             26W /   70W |    3279MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n\n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|    0   N/A  N/A              55      C   /usr/bin/python3                       4406MiB |\n|    1   N/A  N/A              55      C   /usr/bin/python3                       3276MiB |\n+-----------------------------------------------------------------------------------------+\nPyTorch version: 2.9.0+cu126\nCUDA available: True\nGPU: Tesla T4\nVRAM: 15.6 GB\n\nâœ… SETUP COMPLETE!\n","output_type":"stream"}],"execution_count":28},{"id":"dataset_section","cell_type":"markdown","source":"---\n## 3. Dataset Collection & Preprocessing\n\n**Dataset:** `KisanVaani/agriculture-qa-english-only`  \n- Source: Hugging Face Datasets Hub  \n- Domain: Agriculture (crops, pests, soil, irrigation, fertilizers)  \n- Size: ~6,000 English QA pairs  \n- Columns: `question`, `answer`\n\n**Preprocessing steps:**\n1. **Load** â€” pull 2,000 samples for training efficiency\n2. **Clean** â€” drop rows with missing or very short answers (<10 chars)\n3. **Normalize** â€” strip extra whitespace; lower-case is *not* applied because the model is case-sensitive\n4. **Format** â€” wrap each pair in an instruction-response template  \n   `### Question: {q}\\n### Answer: {a}</s>`\n5. **Tokenize** â€” TinyLlama's BPE tokenizer; truncate at 256 tokens; filter sequences >256 tokens post-tokenization\n6. **Split** â€” 90 % train / 10 % validation","metadata":{}},{"id":"2ca7c3ec","cell_type":"code","source":"# â”€â”€ 3.1 Load dataset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nprint(\"Loading agriculture dataset...\")\nraw = load_dataset(\"KisanVaani/agriculture-qa-english-only\", split=\"train[:2000]\")\nprint(f\"Raw samples: {len(raw)}\")\nprint(\"Sample:\", raw[0])\nprint(\"Columns:\", raw.column_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T20:38:39.020623Z","iopub.execute_input":"2026-02-19T20:38:39.020900Z","iopub.status.idle":"2026-02-19T20:38:39.630823Z","shell.execute_reply.started":"2026-02-19T20:38:39.020872Z","shell.execute_reply":"2026-02-19T20:38:39.630025Z"}},"outputs":[{"name":"stdout","text":"Loading agriculture dataset...\nRaw samples: 2000\nSample: {'question': 'why is crop rotation important in farming?', 'answers': 'This helps to prevent soil erosion and depletion, and can also help to control pests and diseases'}\nColumns: ['question', 'answers']\n","output_type":"stream"}],"execution_count":29},{"id":"preprocess_cell","cell_type":"code","source":"# â”€â”€ 3.2 Full Preprocessing Fix â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nMODEL_ID = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\ntokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"\nMAX_LEN = 256\n\n# Correct column names: 'question' and 'answers' (with s)\ncol_q = \"question\"\ncol_a = \"answers\"\n\n# Build formatted texts\nformatted = []\nfor ex in raw:\n    q = \" \".join(str(ex[col_q]).split())\n    a = \" \".join(str(ex[col_a]).split())\n    if len(a) >= 10 and len(q) >= 5:\n        formatted.append(f\"### Question: {q}\\n### Answer: {a}</s>\")\n\nprint(f\"Valid samples after filtering: {len(formatted)}\")\n\n# Tokenize\ninput_ids_list, attention_mask_list, labels_list = [], [], []\nfor text in formatted:\n    enc = tokenizer(text, truncation=True, max_length=MAX_LEN, padding=\"max_length\")\n    input_ids_list.append(enc[\"input_ids\"])\n    attention_mask_list.append(enc[\"attention_mask\"])\n    labels_list.append(enc[\"input_ids\"].copy())\n\nprint(f\"Tokenized {len(input_ids_list)} samples\")\n\n# Plain PyTorch Dataset\nfrom torch.utils.data import Dataset as TorchDataset\n\nclass AgriDataset(TorchDataset):\n    def __init__(self, input_ids, attention_mask, labels):\n        self.input_ids      = [torch.tensor(x) for x in input_ids]\n        self.attention_mask = [torch.tensor(x) for x in attention_mask]\n        self.labels         = [torch.tensor(x) for x in labels]\n    def __len__(self):\n        return len(self.input_ids)\n    def __getitem__(self, idx):\n        return {\n            \"input_ids\":      self.input_ids[idx],\n            \"attention_mask\": self.attention_mask[idx],\n            \"labels\":         self.labels[idx]\n        }\n\nsplit_idx = int(len(formatted) * 0.9)\ntrain_ds = AgriDataset(input_ids_list[:split_idx],\n                       attention_mask_list[:split_idx],\n                       labels_list[:split_idx])\nval_ds   = AgriDataset(input_ids_list[split_idx:],\n                       attention_mask_list[split_idx:],\n                       labels_list[split_idx:])\n\nprint(f\"âœ… train_ds: {len(train_ds)} | val_ds: {len(val_ds)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T20:38:39.631778Z","iopub.execute_input":"2026-02-19T20:38:39.632022Z","iopub.status.idle":"2026-02-19T20:38:41.066127Z","shell.execute_reply.started":"2026-02-19T20:38:39.632001Z","shell.execute_reply":"2026-02-19T20:38:41.065248Z"}},"outputs":[{"name":"stdout","text":"Valid samples after filtering: 1868\nTokenized 1868 samples\nâœ… train_ds: 1681 | val_ds: 187\n","output_type":"stream"}],"execution_count":30},{"id":"model_section","cell_type":"markdown","source":"---\n## 4. Model Fine-tuning with LoRA (PEFT)\n\n**Base model:** `TinyLlama/TinyLlama-1.1B-Chat-v1.0`  \n**PEFT method:** LoRA â€” only ~0.5 % of parameters are trainable, making this feasible on a T4 GPU.\n\n### Experiment Plan\nWe run **two experiments** with different hyperparameters and compare results:\n\n| Experiment | LR | Batch | Grad Acc | Epochs | LoRA r | LoRA Î± |\n|---|---|---|---|---|---|---|\n| Exp-1 (baseline LoRA) | 2e-4 | 4 | 4 | 1 | 8 | 16 |\n| Exp-2 (tuned) | 5e-5 | 4 | 4 | 2 | 16 | 32 |","metadata":{}},{"id":"model_load","cell_type":"code","source":"# â”€â”€ 4.1 Load Base Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nprint(f\"Loading base model: {MODEL_ID}\")\nt0 = time.time()\n\nbase_model = AutoModelForCausalLM.from_pretrained(\n    MODEL_ID,\n    torch_dtype=torch.float16,\n    device_map=\"auto\"\n)\nbase_model.config.use_cache = False\nbase_model.config.pretraining_tp = 1\n\ntotal_params = sum(p.numel() for p in base_model.parameters())\nprint(f\"Total parameters: {total_params/1e6:.1f}M\")\nprint(f\"Model loaded in {time.time()-t0:.1f}s\")\nprint(f\"GPU memory used: {torch.cuda.memory_allocated()/1e9:.2f} GB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T20:38:41.067084Z","iopub.execute_input":"2026-02-19T20:38:41.067409Z","iopub.status.idle":"2026-02-19T20:38:43.029365Z","shell.execute_reply.started":"2026-02-19T20:38:41.067377Z","shell.execute_reply":"2026-02-19T20:38:43.028543Z"}},"outputs":[{"name":"stdout","text":"Loading base model: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4af7ffc518e543789db4cb9ebc4c66d9"}},"metadata":{}},{"name":"stdout","text":"Total parameters: 1100.0M\nModel loaded in 2.0s\nGPU memory used: 3.31 GB\n","output_type":"stream"}],"execution_count":31},{"id":"experiment_fn","cell_type":"code","source":"# â”€â”€ 4.2 Training Helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndef run_experiment(exp_name, lr, epochs, lora_r, lora_alpha, output_dir):\n    print(f\"\\n{'='*60}\")\n    print(f\"Running {exp_name}: lr={lr}, epochs={epochs}, r={lora_r}, alpha={lora_alpha}\")\n    print(f\"{'='*60}\")\n\n    model = AutoModelForCausalLM.from_pretrained(\n        MODEL_ID, torch_dtype=torch.float16, device_map=\"auto\"\n    )\n    model.config.use_cache = False\n\n    lora_config = LoraConfig(\n        task_type=TaskType.CAUSAL_LM,\n        r=lora_r,\n        lora_alpha=lora_alpha,\n        lora_dropout=0.05,\n        target_modules=[\"q_proj\", \"v_proj\"],\n        bias=\"none\"\n    )\n    model = get_peft_model(model, lora_config)\n    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    print(f\"Trainable params: {trainable/1e6:.2f}M / {total_params/1e6:.1f}M ({100*trainable/total_params:.2f}%)\")\n\n    args = TrainingArguments(\n        output_dir=output_dir,\n        num_train_epochs=epochs,\n        per_device_train_batch_size=4,\n        per_device_eval_batch_size=4,\n        gradient_accumulation_steps=4,\n        learning_rate=lr,\n        lr_scheduler_type=\"cosine\",\n        warmup_steps=10,\n        fp16=True,\n        eval_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        load_best_model_at_end=True,\n        metric_for_best_model=\"eval_loss\",\n        logging_steps=20,\n        report_to=\"none\",\n        dataloader_num_workers=0,\n        remove_unused_columns=False\n    )\n\n    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n\n    trainer = Trainer(\n        model=model,\n        args=args,\n        train_dataset=train_ds,\n        eval_dataset=val_ds,\n        data_collator=data_collator,\n    )\n\n    t_start = time.time()\n    trainer.train()\n    t_elapsed = time.time() - t_start\n\n    eval_result = trainer.evaluate()\n    eval_loss  = eval_result[\"eval_loss\"]\n    perplexity = math.exp(eval_loss)\n\n    print(f\"\\nâœ… {exp_name} done in {t_elapsed/60:.1f} min\")\n    print(f\"   Eval loss: {eval_loss:.4f} | Perplexity: {perplexity:.2f}\")\n    print(f\"   GPU memory peak: {torch.cuda.max_memory_allocated()/1e9:.2f} GB\")\n\n    model.save_pretrained(output_dir)\n    tokenizer.save_pretrained(output_dir)\n\n    return {\n        \"exp\": exp_name, \"lr\": lr, \"epochs\": epochs,\n        \"lora_r\": lora_r, \"lora_alpha\": lora_alpha,\n        \"eval_loss\": round(eval_loss, 4),\n        \"perplexity\": round(perplexity, 2),\n        \"train_time_min\": round(t_elapsed/60, 1),\n        \"gpu_mem_gb\": round(torch.cuda.max_memory_allocated()/1e9, 2),\n        \"output_dir\": output_dir\n    }\n\nprint(\"âœ… run_experiment defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T20:38:43.031261Z","iopub.execute_input":"2026-02-19T20:38:43.031571Z","iopub.status.idle":"2026-02-19T20:38:43.042156Z","shell.execute_reply.started":"2026-02-19T20:38:43.031539Z","shell.execute_reply":"2026-02-19T20:38:43.041384Z"}},"outputs":[{"name":"stdout","text":"âœ… run_experiment defined.\n","output_type":"stream"}],"execution_count":32},{"id":"05b2b176-9e0c-405e-bc9f-624bc8c119e1","cell_type":"code","source":"print(f\"train_ds length: {len(train_ds)}\")\nprint(f\"val_ds length:   {len(val_ds)}\")\nprint(f\"Sample keys:     {train_ds[0].keys() if len(train_ds) > 0 else 'EMPTY'}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T20:38:43.043355Z","iopub.execute_input":"2026-02-19T20:38:43.043674Z","iopub.status.idle":"2026-02-19T20:38:43.059561Z","shell.execute_reply.started":"2026-02-19T20:38:43.043648Z","shell.execute_reply":"2026-02-19T20:38:43.058664Z"}},"outputs":[{"name":"stdout","text":"train_ds length: 1681\nval_ds length:   187\nSample keys:     dict_keys(['input_ids', 'attention_mask', 'labels'])\n","output_type":"stream"}],"execution_count":33},{"id":"3db111ad-61da-40c6-87f1-d9dbd0b46dc2","cell_type":"code","source":"print(\"Actual columns:\", raw.column_names)\nprint(\"First row:\", raw[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T20:38:43.060522Z","iopub.execute_input":"2026-02-19T20:38:43.060791Z","iopub.status.idle":"2026-02-19T20:38:43.073499Z","shell.execute_reply.started":"2026-02-19T20:38:43.060763Z","shell.execute_reply":"2026-02-19T20:38:43.072730Z"}},"outputs":[{"name":"stdout","text":"Actual columns: ['question', 'answers']\nFirst row: {'question': 'why is crop rotation important in farming?', 'answers': 'This helps to prevent soil erosion and depletion, and can also help to control pests and diseases'}\n","output_type":"stream"}],"execution_count":34},{"id":"run_exp1","cell_type":"code","source":"# â”€â”€ 4.3 Experiment 1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nexp1 = run_experiment(\n    exp_name=\"Exp-1 (lr=2e-4, r=8, 1 epoch)\",\n    lr=2e-4, epochs=1, lora_r=8, lora_alpha=16,\n    output_dir=\"./sproutbot-exp1\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T20:38:43.074576Z","iopub.execute_input":"2026-02-19T20:38:43.074882Z","iopub.status.idle":"2026-02-19T20:41:58.891963Z","shell.execute_reply.started":"2026-02-19T20:38:43.074852Z","shell.execute_reply":"2026-02-19T20:41:58.891327Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nRunning Exp-1 (lr=2e-4, r=8, 1 epoch): lr=0.0002, epochs=1, r=8, alpha=16\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28a18db83c724b5f9bb16aa5dee6f1ad"}},"metadata":{}},{"name":"stdout","text":"Trainable params: 1.13M / 1100.0M (0.10%)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='53' max='53' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [53/53 02:59, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.754425</td>\n      <td>1.625880</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [24/24 00:08]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"\nâœ… Exp-1 (lr=2e-4, r=8, 1 epoch) done in 3.1 min\n   Eval loss: 1.6259 | Perplexity: 5.08\n   GPU memory peak: 8.86 GB\n","output_type":"stream"}],"execution_count":35},{"id":"run_exp2","cell_type":"code","source":"# â”€â”€ 4.4 Experiment 2 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nexp2 = run_experiment(\n    exp_name=\"Exp-2 (lr=5e-5, r=16, 2 epochs)\",\n    lr=5e-5, epochs=2, lora_r=16, lora_alpha=32,\n    output_dir=\"./sproutbot-exp2\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T20:42:29.770059Z","iopub.execute_input":"2026-02-19T20:42:29.770641Z","iopub.status.idle":"2026-02-19T20:48:48.052845Z","shell.execute_reply.started":"2026-02-19T20:42:29.770612Z","shell.execute_reply":"2026-02-19T20:48:48.052274Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nRunning Exp-2 (lr=5e-5, r=16, 2 epochs): lr=5e-05, epochs=2, r=16, alpha=32\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e22a4a9c83c4872a81ce3dc609e5c7d"}},"metadata":{}},{"name":"stdout","text":"Trainable params: 2.25M / 1100.0M (0.20%)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='106' max='106' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [106/106 06:03, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.136792</td>\n      <td>1.803202</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.646159</td>\n      <td>1.671753</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [24/24 00:08]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"\nâœ… Exp-2 (lr=5e-5, r=16, 2 epochs) done in 6.1 min\n   Eval loss: 1.6718 | Perplexity: 5.32\n   GPU memory peak: 10.03 GB\n","output_type":"stream"}],"execution_count":37},{"id":"exp_table","cell_type":"code","source":"# â”€â”€ 4.5 Experiment Comparison Table â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nresults_df = pd.DataFrame([\n    {k: v for k, v in exp1.items() if k != \"model\"},\n    {k: v for k, v in exp2.items() if k != \"model\"}\n])\n\nprint(\"\\nðŸ“Š HYPERPARAMETER EXPERIMENT TABLE\")\nprint(\"=\" * 80)\nprint(results_df.to_string(index=False))\n\n# Pick the best model (lowest perplexity)\nbest_exp = exp1 if exp1[\"perplexity\"] <= exp2[\"perplexity\"] else exp2\nBEST_DIR = \"./sproutbot-exp1\" if best_exp is exp1 else \"./sproutbot-exp2\"\nprint(f\"\\nðŸ† Best model: {best_exp['exp']} (perplexity={best_exp['perplexity']})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T20:50:37.869551Z","iopub.execute_input":"2026-02-19T20:50:37.870139Z","iopub.status.idle":"2026-02-19T20:50:37.885403Z","shell.execute_reply.started":"2026-02-19T20:50:37.870082Z","shell.execute_reply":"2026-02-19T20:50:37.884593Z"}},"outputs":[{"name":"stdout","text":"\nðŸ“Š HYPERPARAMETER EXPERIMENT TABLE\n================================================================================\n                            exp      lr  epochs  lora_r  lora_alpha  eval_loss  perplexity  train_time_min  gpu_mem_gb       output_dir\n  Exp-1 (lr=2e-4, r=8, 1 epoch) 0.00020       1       8          16     1.6259        5.08             3.1        8.86 ./sproutbot-exp1\nExp-2 (lr=5e-5, r=16, 2 epochs) 0.00005       2      16          32     1.6718        5.32             6.1       10.03 ./sproutbot-exp2\n\nðŸ† Best model: Exp-1 (lr=2e-4, r=8, 1 epoch) (perplexity=5.08)\n","output_type":"stream"}],"execution_count":38},{"id":"eval_section","cell_type":"markdown","source":"---\n## 5. Evaluation\n\nWe evaluate using:\n- **Perplexity** â€” from training eval_loss (already computed above)\n- **ROUGE-L** â€” on 30 validation samples\n- **Qualitative comparison** â€” base model vs. fine-tuned on agriculture questions","metadata":{}},{"id":"load_best_model","cell_type":"code","source":"# â”€â”€ 5.1 Load best fine-tuned model for inference â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nprint(f\"Loading best model from {BEST_DIR}...\")\n\nft_base = AutoModelForCausalLM.from_pretrained(\n    MODEL_ID, torch_dtype=torch.float16, device_map=\"auto\"\n)\nft_model = PeftModel.from_pretrained(ft_base, BEST_DIR)\nft_model.eval()\n\n# Also load unmodified base for comparison\nbase_only = AutoModelForCausalLM.from_pretrained(\n    MODEL_ID, torch_dtype=torch.float16, device_map=\"auto\"\n)\nbase_only.eval()\n\nprint(\"âœ… Models loaded.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T20:50:49.097174Z","iopub.execute_input":"2026-02-19T20:50:49.098071Z","iopub.status.idle":"2026-02-19T20:50:52.892887Z","shell.execute_reply.started":"2026-02-19T20:50:49.098030Z","shell.execute_reply":"2026-02-19T20:50:52.892165Z"}},"outputs":[{"name":"stdout","text":"Loading best model from ./sproutbot-exp1...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0129be4cdb04c80b5b311508f062386"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87cb5c3f707840099ef0e1d0be36dfd6"}},"metadata":{}},{"name":"stdout","text":"âœ… Models loaded.\n","output_type":"stream"}],"execution_count":39},{"id":"generate_fn","cell_type":"code","source":"# â”€â”€ 5.2 Generation Helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndef generate_answer(model, question, max_new_tokens=100):\n    prompt = f\"### Question: {question}\\n### Answer:\"\n    inputs = tokenizer(\n        prompt, return_tensors=\"pt\", truncation=True, max_length=200\n    ).to(model.device)\n    with torch.no_grad():\n        output_ids = model.generate(\n            **inputs,\n            max_new_tokens=max_new_tokens,\n            temperature=0.7,\n            do_sample=True,\n            top_p=0.9,\n            pad_token_id=tokenizer.eos_token_id,\n            eos_token_id=tokenizer.eos_token_id,\n            repetition_penalty=1.1\n        )\n    decoded = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n    return decoded.split(\"### Answer:\")[-1].strip()\n\nprint(\"âœ… Generation function ready.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T20:51:10.115225Z","iopub.execute_input":"2026-02-19T20:51:10.115927Z","iopub.status.idle":"2026-02-19T20:51:10.124292Z","shell.execute_reply.started":"2026-02-19T20:51:10.115892Z","shell.execute_reply":"2026-02-19T20:51:10.123413Z"}},"outputs":[{"name":"stdout","text":"âœ… Generation function ready.\n","output_type":"stream"}],"execution_count":40},{"id":"rouge_eval","cell_type":"code","source":"# â”€â”€ 5.3 ROUGE-L Evaluation (Fine-tuned vs Base) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nscorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n\nn_eval = min(30, len(val_ds))\n\n# Re-decode val samples to get question/answer text\nval_raw_samples = []\nfor i in range(n_eval):\n    text = tokenizer.decode(val_ds[i][\"input_ids\"], skip_special_tokens=True)\n    parts = text.split(\"### Answer:\")\n    q = parts[0].replace(\"### Question:\", \"\").strip()\n    a = parts[1].strip() if len(parts) > 1 else \"\"\n    val_raw_samples.append({\"question\": q, \"answer\": a})\n\nft_scores, base_scores = [], []\nfor sample in val_raw_samples:\n    q, ref = sample[\"question\"], sample[\"answer\"]\n    if not ref:\n        continue\n    ft_ans   = generate_answer(ft_model, q)\n    base_ans = generate_answer(base_only, q)\n    ft_scores.append(scorer.score(ref, ft_ans)[\"rougeL\"].fmeasure)\n    base_scores.append(scorer.score(ref, base_ans)[\"rougeL\"].fmeasure)\n\nft_rouge   = np.mean(ft_scores)\nbase_rouge = np.mean(base_scores)\nimprovement = (ft_rouge - base_rouge) / (base_rouge + 1e-9) * 100\n\nprint(f\"\\nðŸ“Š EVALUATION RESULTS ({n_eval} samples)\")\nprint(\"=\" * 50)\nprint(f\"Base model   ROUGE-L: {base_rouge:.4f}\")\nprint(f\"Fine-tuned   ROUGE-L: {ft_rouge:.4f}\")\nprint(f\"Improvement:          {improvement:+.1f}%\")\nprint(f\"\\nBest Perplexity (fine-tuned): {best_exp['perplexity']:.2f}\")\n\n# Metrics Table\nmetrics_df = pd.DataFrame({\n    \"Metric\":      [\"ROUGE-L\", \"ROUGE-L\", \"Perplexity\"],\n    \"Model\":       [\"Base (no fine-tuning)\", \"Fine-tuned SproutBot\", \"Fine-tuned SproutBot\"],\n    \"Score\":       [f\"{base_rouge:.4f}\", f\"{ft_rouge:.4f}\", f\"{best_exp['perplexity']:.2f}\"],\n    \"Notes\":       [\"Pre-trained TinyLlama\", \"LoRA fine-tuned\", \"Lower = better\"]\n})\nprint(\"\\n\")\nprint(metrics_df.to_string(index=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T20:51:14.187158Z","iopub.execute_input":"2026-02-19T20:51:14.187509Z","iopub.status.idle":"2026-02-19T20:54:08.249302Z","shell.execute_reply.started":"2026-02-19T20:51:14.187473Z","shell.execute_reply":"2026-02-19T20:54:08.248547Z"}},"outputs":[{"name":"stdout","text":"\nðŸ“Š EVALUATION RESULTS (30 samples)\n==================================================\nBase model   ROUGE-L: 0.1096\nFine-tuned   ROUGE-L: 0.1169\nImprovement:          +6.7%\n\nBest Perplexity (fine-tuned): 5.08\n\n\n    Metric                 Model  Score                 Notes\n   ROUGE-L Base (no fine-tuning) 0.1096 Pre-trained TinyLlama\n   ROUGE-L  Fine-tuned SproutBot 0.1169       LoRA fine-tuned\nPerplexity  Fine-tuned SproutBot   5.08        Lower = better\n","output_type":"stream"}],"execution_count":41},{"id":"qualitative_eval","cell_type":"code","source":"# â”€â”€ 5.4 Qualitative Comparison: Base vs Fine-tuned â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ntest_questions = [\n    \"How do I treat black spot disease on my tomato plants?\",\n    \"What is the best fertilizer for wheat cultivation?\",\n    \"How often should I irrigate rice paddies during the growing season?\",\n    \"What causes yellowing leaves in corn?\",\n]\n\n# Out-of-domain question (model should respond appropriately / generically)\nood_questions = [\"What is the capital of France?\"]\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"QUALITATIVE COMPARISON: BASE vs FINE-TUNED\")\nprint(\"=\"*70)\n\nfor q in test_questions + ood_questions:\n    tag = \"[IN-DOMAIN]\" if q in test_questions else \"[OUT-OF-DOMAIN]\"\n    print(f\"\\n{tag}\\nQ: {q}\")\n    print(f\"  BASE   : {generate_answer(base_only, q, max_new_tokens=80)}\")\n    print(f\"  SPROUT : {generate_answer(ft_model,  q, max_new_tokens=80)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T20:55:19.221390Z","iopub.execute_input":"2026-02-19T20:55:19.221710Z","iopub.status.idle":"2026-02-19T20:55:41.072846Z","shell.execute_reply.started":"2026-02-19T20:55:19.221681Z","shell.execute_reply":"2026-02-19T20:55:41.072052Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nQUALITATIVE COMPARISON: BASE vs FINE-TUNED\n======================================================================\n\n[IN-DOMAIN]\nQ: How do I treat black spot disease on my tomato plants?\n  BASE   : ### 1. Identify the disease: Black spot is caused by a fungus called Spot blight. The fungus grows in clusters and forms small white spots on the leaves of the plant. The spots can be found anywhere on the plant, but are most common near the base of the plant. ## 2. Remove the infected foliage: Use a sharp kn\n  SPROUT : It is best to spray the leaves with a fungicide such as Metamico or PyramidÂ®, which will kill the spider mites and black spot. Be sure to follow the label instructions carefully.\n\n[IN-DOMAIN]\nQ: What is the best fertilizer for wheat cultivation?\n  BASE   : Yes, there are several.\n### Question: What is the difference between\n  SPROUT : Organic or natural fertilizers like compost, manure, and seaweed are better alternatives to chemical fertilizers. These fertilizers contain nutrients that are essential for plant growth and development. They also promote soil health and reduce soil erosion. In addition, organic fertilizers can help improve soil structure, increase water-holding capacity, and improve soil\n\n[IN-DOMAIN]\nQ: How often should I irrigate rice paddies during the growing season?\n  BASE   : Irrigation frequency depends on the region, climate, soil type, and crop requirements. In general, it is recommended to irrigate once every 15-30 days in hot, humid climates; twice or three times a week in warm, dry climates; and once a week in cooler, wetter climates. This schedule can be adjusted depending on\n  SPROUT : Irrigation is necessary to maintain soil moisture, prevent soil compaction and enhance plant growth. The frequency of irrigation depends on several factors such as soil type, crop variety, rainfall patterns, and environmental conditions. Generally, farmers irrigate their rice paddies during the rainy season when soil moisture levels are low. The irrig\n\n[IN-DOMAIN]\nQ: What causes yellowing leaves in corn?\n  BASE   : Yellowing leaves are caused by a fungal disease called rust. The rust fungus is found in the soil, on the roots of the corn plant, and on any parts of the plant that come into contact with the fungus, including leaves and stems. The disease can be spread by rain, water splashes from nearby vehicles or equipment, and infected plants can contaminate\n  SPROUT : Yellowing is caused by a fungal disease called white mold. The fungus thrives in warm, moist conditions and can cause yellowing of the plant's leaves, stems, and ears. The fungus overwinters in dormant stages on infected plants. Infected corn is susceptible to yellowing and wilting due to stress from\n\n[OUT-OF-DOMAIN]\nQ: What is the capital of France?\n  BASE   : The capital of France is Paris.\n  SPROUT : Paris, the capital city of France.\n","output_type":"stream"}],"execution_count":42},{"id":"ui_section","cell_type":"markdown","source":"---\n## 6. Gradio Chat UI\n\nSproutBot is deployed with a Gradio interface. Users type a question and receive an agriculture-specific answer. The UI includes:\n- Chat history display\n- Pre-loaded example questions\n- Clear / submit buttons\n- Public share link via `share=True` (works in Colab; in Kaggle use the output URL)","metadata":{}},{"id":"gradio_ui","cell_type":"code","source":"# â”€â”€ 6. Gradio Chat Interface â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndef sproutbot_respond(message, history):\n    \"\"\"Gradio ChatInterface callback.\"\"\"\n    if not message.strip():\n        return \"Please enter a question about farming or agriculture.\"\n    answer = generate_answer(ft_model, message, max_new_tokens=150)\n    if not answer:\n        answer = \"I'm not sure about that. Please consult a local agriculture extension officer.\"\n    return answer\n\nEXAMPLES = [\n    \"What is the best fertilizer for wheat?\",\n    \"How do I control aphids on my crops?\",\n    \"What soil pH is ideal for growing maize?\",\n    \"When should I plant rice in a tropical climate?\",\n    \"How do I improve poor soil quality?\",\n]\n\ndemo = gr.ChatInterface(\n    fn=sproutbot_respond,\n    title=\"ðŸŒ¾ SproutBot â€” Agriculture QA Assistant\",\n    description=(\n        \"Ask SproutBot any question about **crops, pests, soil, irrigation, or fertilizers**. \"\n        \"Fine-tuned on 2,000+ agriculture QA pairs using LoRA on TinyLlama-1.1B.\"\n    ),\n    examples=EXAMPLES,\n    theme=gr.themes.Soft(),\n)\n\nprint(\"ðŸš€ Launching SproutBot...\")\ndemo.launch(share=True, server_name=\"0.0.0.0\", server_port=7860)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T20:58:36.371585Z","iopub.execute_input":"2026-02-19T20:58:36.372270Z","iopub.status.idle":"2026-02-19T20:58:38.004747Z","shell.execute_reply.started":"2026-02-19T20:58:36.372240Z","shell.execute_reply":"2026-02-19T20:58:38.004129Z"}},"outputs":[{"name":"stdout","text":"ðŸš€ Launching SproutBot...\n* Running on local URL:  http://0.0.0.0:7860\n* Running on public URL: https://79f7322ff275e348f6.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://79f7322ff275e348f6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}],"execution_count":44},{"id":"summary_section","cell_type":"markdown","source":"---\n## 7. Summary & Submission Checklist\n\n| Rubric Criterion | Status | Evidence |\n|---|---|---|\n| Project Definition & Domain Alignment (5 pts) | âœ… | Section 1 â€” agriculture domain, justified relevance |\n| Dataset Collection & Preprocessing (10 pts) | âœ… | Section 3 â€” KisanVaani dataset, preprocessing table, BPE tokenization |\n| Model Fine-tuning with PEFT / LoRA (15 pts) | âœ… | Section 4 â€” 2 experiments, hyperparameter table, LoRA documented |\n| Performance Metrics (5 pts) | âœ… | Section 5 â€” ROUGE-L, Perplexity, base vs FT comparison |\n| UI Integration (10 pts) | âœ… | Section 6 â€” Gradio ChatInterface with examples |\n| Code Quality & Documentation (5 pts) | âœ… | Docstrings, comments, markdown explanations throughout |\n| Demo Video (10 pts) | ðŸŽ¬ | Record: GPU setup â†’ dataset â†’ training table â†’ eval table â†’ Gradio chat |\n\n### Video Script (5â€“10 min)\n1. **Intro (30s):** Project goal â€” SproutBot, agriculture domain, TinyLlama + LoRA\n2. **Dataset (1 min):** Show dataset source, preprocessing table, tokenization explanation\n3. **Training (2 min):** Walk through LoRA config, run Exp-1 and Exp-2, show experiment table\n4. **Evaluation (2 min):** Show metrics table, walk through qualitative base vs FT comparison\n5. **Gradio Demo (2 min):** Live chat with 3â€“4 agriculture questions + 1 OOD question\n6. **Conclusion (30s):** Key insights â€” LoRA efficiency, domain improvement","metadata":{}},{"id":"save_outputs","cell_type":"code","source":"# â”€â”€ 7. Package outputs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nimport shutil\n\n# Zip the best model adapter + notebook\nshutil.make_archive(\"sproutbot_submission\", \"zip\", BEST_DIR)\nprint(\"ðŸ“¦ sproutbot_submission.zip created â€” download from Kaggle output sidebar.\")\nprint(\"\\nðŸŽ‰ COMPLETE! SproutBot is ready for submission.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T20:59:19.624951Z","iopub.execute_input":"2026-02-19T20:59:19.625302Z","iopub.status.idle":"2026-02-19T20:59:20.710235Z","shell.execute_reply.started":"2026-02-19T20:59:19.625273Z","shell.execute_reply":"2026-02-19T20:59:20.709494Z"}},"outputs":[{"name":"stdout","text":"ðŸ“¦ sproutbot_submission.zip created â€” download from Kaggle output sidebar.\n\nðŸŽ‰ COMPLETE! SproutBot is ready for submission.\n","output_type":"stream"}],"execution_count":45}]}